{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b91df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¦ Collecting data for TheGrefg...\n",
      "âœ… Profile saved for TheGrefg\n",
      "âœ… Tweets saved for TheGrefg\n",
      "âœ… Followers saved for TheGrefg\n",
      "âœ… Following saved for TheGrefg\n",
      "\n",
      "ðŸ“¦ Collecting data for Jynxzi...\n",
      "âœ… Profile saved for Jynxzi\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "âœ… Tweets saved for Jynxzi\n",
      "âœ… Followers saved for Jynxzi\n",
      "âœ… Following saved for Jynxzi\n",
      "\n",
      "ðŸ“¦ Collecting data for markiplier...\n",
      "âœ… Profile saved for markiplier\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "âœ… Tweets saved for markiplier\n",
      "âœ… Followers saved for markiplier\n",
      "âœ… Following saved for markiplier\n",
      "\n",
      "ðŸ“¦ Collecting data for SSSniperWolf...\n",
      "âœ… Profile saved for SSSniperWolf\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "âœ… Tweets saved for SSSniperWolf\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "âœ… Followers saved for SSSniperWolf\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "âœ… Following saved for SSSniperWolf\n",
      "\n",
      "ðŸ“¦ Collecting data for OMGitsAliA...\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "âœ… Profile saved for OMGitsAliA\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "âœ… Tweets saved for OMGitsAliA\n",
      "âœ… Followers saved for OMGitsAliA\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "âœ… Following saved for OMGitsAliA\n",
      "\n",
      "ðŸ“¦ Collecting data for scump...\n",
      "âœ… Profile saved for scump\n",
      "âœ… Tweets saved for scump\n",
      "âœ… Followers saved for scump\n",
      "âœ… Following saved for scump\n",
      "\n",
      "ðŸ“¦ Collecting data for LazarBeam...\n",
      "âœ… Profile saved for LazarBeam\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "âœ… Tweets saved for LazarBeam\n",
      "âœ… Followers saved for LazarBeam\n",
      "âœ… Following saved for LazarBeam\n",
      "\n",
      "ðŸ“¦ Collecting data for Pokelawls...\n",
      "âœ… Profile saved for Pokelawls\n",
      "â³ 429 Too Many Requests. Retrying in 0.5s...\n",
      "âœ… Tweets saved for Pokelawls\n",
      "âœ… Followers saved for Pokelawls\n",
      "âœ… Following saved for Pokelawls\n",
      "\n",
      "ðŸŽ‰ All data collected and saved per influencer.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "# Load API keys\n",
    "load_dotenv()\n",
    "BASE_URL = \"https://twitter241.p.rapidapi.com\"\n",
    "HEADERS = {\n",
    "    \"x-rapidapi-host\": \"twitter241.p.rapidapi.com\",\n",
    "    \"x-rapidapi-key\": \"056375d7f5mshd4546f4fb1a7f4ep129c82jsna85290da7d03\"\n",
    "}\n",
    "\n",
    "Influencer list\n",
    "INFLUENCER_USERNAMES = [\n",
    "    \"Ninja\", \"shroud\", \"Myth_\", \"DrLupo\", \"TimTheTatman\", \"Syndicate\", \"Summit1g\", \"Pokimane\",\n",
    "    \"Tfue\", \"Jacksepticeye\", \"Valkyrae\", \"Quackity\", \"TheGrefg\", \"Jynxzi\", \"markiplier\",\n",
    "    \"SSSniperWolf\", \"OMGitsAliA\", \"scump\", \"LazarBeam\", \"Pokelawls\"\n",
    "]\n",
    "\n",
    "\n",
    "# Retry decorator for 429 errors\n",
    "# Retry decorator: infinite retries with no delay\n",
    "\n",
    "\n",
    "def retry_on_429():\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            while True:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except HTTPError as e:\n",
    "                    if e.response.status_code == 429:\n",
    "                        print(f\"â³ 429 Too Many Requests. Retrying in 0.5s...\")\n",
    "                        time.sleep(0.5)\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "\n",
    "# API calls\n",
    "@retry_on_429()\n",
    "def get_user_info(username):\n",
    "    url = f\"{BASE_URL}/user\"\n",
    "    params = {\"username\": username}\n",
    "    response = requests.get(url, headers=HEADERS, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "@retry_on_429()\n",
    "def get_user_followers(user_id, count=100):\n",
    "    url = f\"{BASE_URL}/followers\"\n",
    "    params = {\"user\": user_id, \"count\": count}\n",
    "    response = requests.get(url, headers=HEADERS, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "@retry_on_429()\n",
    "def get_user_following(user_id, count=100):\n",
    "    url = f\"{BASE_URL}/followings\"\n",
    "    params = {\"user\": user_id, \"count\": count}\n",
    "    response = requests.get(url, headers=HEADERS, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "@retry_on_429()\n",
    "def get_user_tweets(user_id, count=50):\n",
    "    url = f\"{BASE_URL}/user-tweets\"\n",
    "    params = {\"user\": user_id, \"count\": count}\n",
    "    response = requests.get(url, headers=HEADERS, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Output folders\n",
    "os.makedirs(\"data/raw/profiles\", exist_ok=True)\n",
    "os.makedirs(\"data/raw/followers\", exist_ok=True)\n",
    "os.makedirs(\"data/raw/following\", exist_ok=True)\n",
    "os.makedirs(\"data/raw/tweets\", exist_ok=True)\n",
    "\n",
    "# Collect data\n",
    "for username in INFLUENCER_USERNAMES:\n",
    "    print(f\"\\nðŸ“¦ Collecting data for {username}...\")\n",
    "\n",
    "    user_info = get_user_info(username)\n",
    "    if not user_info:\n",
    "        print(f\"âš ï¸ Failed to fetch user info for {username}\")\n",
    "        continue\n",
    "\n",
    "    # Extract user ID from nested structure\n",
    "    user_data = user_info.get(\"result\", {}).get(\"data\", {}).get(\"user\", {}).get(\"result\", {})\n",
    "    user_id = user_data.get(\"rest_id\")\n",
    "\n",
    "    if not user_id:\n",
    "        print(f\"âŒ User ID not found for {username}\")\n",
    "        continue\n",
    "\n",
    "    # Save profile\n",
    "    with open(f\"data/raw/profiles/{username}.json\", \"w\") as f:\n",
    "        json.dump(user_info, f, indent=2)\n",
    "    print(f\"âœ… Profile saved for {username}\")\n",
    "\n",
    "    # Get and save tweets\n",
    "    tweets = get_user_tweets(user_id)\n",
    "    if tweets:\n",
    "        with open(f\"data/raw/tweets/{username}.json\", \"w\") as f:\n",
    "            json.dump([{\"tweets\": tweets}], f, indent=2)\n",
    "        print(f\"âœ… Tweets saved for {username}\")\n",
    "\n",
    "    # Get and save followers\n",
    "    followers = get_user_followers(user_id)\n",
    "    if followers:\n",
    "        with open(f\"data/raw/followers/{username}.json\", \"w\") as f:\n",
    "            json.dump(followers, f, indent=2)\n",
    "        print(f\"âœ… Followers saved for {username}\")\n",
    "\n",
    "    # Get and save following\n",
    "    following = get_user_following(user_id)\n",
    "    if following:\n",
    "        with open(f\"data/raw/following/{username}.json\", \"w\") as f:\n",
    "            json.dump(following, f, indent=2)\n",
    "        print(f\"âœ… Following saved for {username}\")\n",
    "\n",
    "    # Delay to reduce risk of rate limits\n",
    "\n",
    "print(\"\\nðŸŽ‰ All data collected and saved per influencer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "710b36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_json(json_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Extracts and aggregates tweet and profile features from an influencer's tweet JSON file.\"\"\"\n",
    "    \n",
    "    # Load tweet JSON\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract tweets\n",
    "    entries = data[0]['tweets']['result']['timeline']['instructions']\n",
    "    tweet_items = []\n",
    "    for instruction in entries:\n",
    "        if instruction.get('type') == \"TimelineAddEntries\":\n",
    "            for entry in instruction['entries']:\n",
    "                try:\n",
    "                    tweet = entry['content']['itemContent']['tweet_results']['result']\n",
    "                    tweet_items.append(tweet)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "    # Helper: parse timestamp\n",
    "    def parse_datetime(t): return datetime.strptime(t, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "\n",
    "    # Helper: sentiment\n",
    "    def get_sentiment(text):\n",
    "        blob = TextBlob(text)\n",
    "        return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
    "\n",
    "    # Extract features per tweet\n",
    "    records = []\n",
    "    for t in tweet_items:\n",
    "        legacy = t['legacy']\n",
    "        views = t.get('views', {}).get('count', '0')\n",
    "        text = legacy.get('full_text', '')\n",
    "        media = legacy.get('entities', {}).get('media', [])\n",
    "        urls = legacy.get('entities', {}).get('urls', [])\n",
    "        mentions = legacy.get('entities', {}).get('user_mentions', [])\n",
    "        hashtags = legacy.get('entities', {}).get('hashtags', [])\n",
    "        polarity, subjectivity = get_sentiment(text)\n",
    "\n",
    "        views_count = int(views.replace(',', '')) if views else 1\n",
    "        total_engagement = legacy['favorite_count'] + legacy['retweet_count'] + legacy['reply_count']\n",
    "        engagement_rate = total_engagement / views_count if views_count > 0 else 0\n",
    "\n",
    "        records.append({\n",
    "            \"created_at\": parse_datetime(legacy['created_at']),\n",
    "            \"text_length\": len(text),\n",
    "            \"word_count\": len(re.findall(r'\\w+', text)),\n",
    "            \"has_media\": int(bool(media)),\n",
    "            \"has_url\": int(bool(urls)),\n",
    "            \"has_mentions\": int(bool(mentions)),\n",
    "            \"has_hashtags\": int(bool(hashtags)),\n",
    "            \"favorite_count\": legacy['favorite_count'],\n",
    "            \"retweet_count\": legacy['retweet_count'],\n",
    "            \"reply_count\": legacy['reply_count'],\n",
    "            \"bookmark_count\": legacy.get('bookmark_count', 0),\n",
    "            \"views\": views_count,\n",
    "            \"engagement_rate\": engagement_rate,\n",
    "            \"sentiment_polarity\": polarity,\n",
    "            \"sentiment_subjectivity\": subjectivity,\n",
    "            \"hour\": parse_datetime(legacy['created_at']).hour,\n",
    "            \"weekday\": parse_datetime(legacy['created_at']).weekday(),\n",
    "            \"is_weekend\": int(parse_datetime(legacy['created_at']).weekday() >= 5),\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No valid tweets found in JSON.\")\n",
    "\n",
    "    # === Aggregation ===\n",
    "    agg_features = {\n",
    "        \"text_length\": [\"mean\", \"std\", \"max\"],\n",
    "        \"word_count\": [\"mean\", \"std\", \"max\"],\n",
    "        \"has_media\": \"mean\",\n",
    "        \"has_url\": \"mean\",\n",
    "        \"has_mentions\": \"mean\",\n",
    "        \"has_hashtags\": \"mean\",\n",
    "        \"favorite_count\": [\"mean\", \"max\"],\n",
    "        \"retweet_count\": [\"mean\", \"max\"],\n",
    "        \"reply_count\": [\"mean\", \"max\"],\n",
    "        \"bookmark_count\": [\"mean\", \"max\"],\n",
    "        \"views\": [\"mean\", \"max\"],\n",
    "        \"engagement_rate\": [\"mean\", \"max\", \"std\"],\n",
    "        \"sentiment_polarity\": [\"mean\", \"std\"],\n",
    "        \"sentiment_subjectivity\": [\"mean\", \"std\"],\n",
    "        \"hour\": [\"mean\"],\n",
    "        \"is_weekend\": \"mean\"\n",
    "    }\n",
    "\n",
    "    agg_df = df.agg(agg_features)\n",
    "    agg_df.columns = ['{}_{}'.format(col[0], col[1]) if isinstance(col, tuple) else col for col in agg_df.columns]\n",
    "\n",
    "    # === Add user profile features ===\n",
    "    user_info = tweet_items[0]['core']['user_results']['result']['legacy']\n",
    "    created_at_user = parse_datetime(user_info['created_at'])\n",
    "    profile_features = {\n",
    "        \"followers_count\": user_info[\"followers_count\"],\n",
    "        \"friends_count\": user_info[\"friends_count\"],\n",
    "        \"listed_count\": user_info[\"listed_count\"],\n",
    "        \"statuses_count\": user_info[\"statuses_count\"],\n",
    "        \"media_count\": user_info[\"media_count\"],\n",
    "        \"favourites_count\": user_info[\"favourites_count\"],\n",
    "        \"account_age_days\": (datetime.utcnow() - created_at_user.replace(tzinfo=None)).days,\n",
    "        \"follower_following_ratio\": user_info[\"followers_count\"] / (user_info[\"friends_count\"] + 1)\n",
    "    }\n",
    "\n",
    "    final_features = pd.concat([agg_df.reset_index(drop=True), pd.DataFrame([profile_features])], axis=1)\n",
    "    return final_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "872a10cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: TheGrefg\n",
      "âœ… Saved: OMGitsAliA\n",
      "âœ… Saved: LazarBeam\n",
      "âœ… Saved: Myth_\n",
      "âœ… Saved: Jynxzi\n",
      "âŒ Error processing Pokelawls: 'legacy'\n",
      "âœ… Saved: Jacksepticeye\n",
      "âœ… Saved: Summit1g\n",
      "âœ… Saved: scump\n",
      "âœ… Saved: markiplier\n",
      "âœ… Saved: Tfue\n",
      "âœ… Saved: DrLupo\n",
      "âœ… Saved: TimTheTatman\n",
      "âœ… Saved: shroud\n",
      "âœ… Saved: Syndicate\n",
      "âŒ Error processing Pokimane: No valid tweets found in JSON.\n",
      "âœ… Saved: Ninja\n",
      "âŒ Error processing SSSniperWolf: 'legacy'\n",
      "âŒ Error processing Valkyrae: 'legacy'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "input_dir = \"data/raw/tweets/\"\n",
    "output_dir = \"data/outputs/engagement_features/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(input_dir):\n",
    "    if file.endswith(\".json\"):\n",
    "        screen_name = file.replace(\".json\", \"\")\n",
    "        try:\n",
    "            feature_df = extract_features_from_json(os.path.join(input_dir, file))\n",
    "            feature_df.to_csv(f\"{output_dir}/{screen_name}_features.csv\", index=False)\n",
    "            print(f\"âœ… Saved: {screen_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error processing {screen_name}: {e}\")\n",
    "\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_features.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7a240935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Merged dataset for Ninja:\n",
      "                                      0\n",
      "text_length                  104.647059\n",
      "word_count                    18.294118\n",
      "has_media                      0.705882\n",
      "has_url                        0.117647\n",
      "has_mentions                   0.588235\n",
      "has_hashtags                   0.058824\n",
      "favorite_count              3147.411765\n",
      "retweet_count                251.411765\n",
      "reply_count                   56.882353\n",
      "bookmark_count               251.176471\n",
      "views                     217888.705882\n",
      "engagement_rate               18.627375\n",
      "sentiment_polarity             0.172638\n",
      "sentiment_subjectivity         0.292157\n",
      "hour                          16.235294\n",
      "is_weekend                     0.235294\n",
      "followers_count               6527829.0\n",
      "friends_count                    1516.0\n",
      "listed_count                     3577.0\n",
      "statuses_count                  46063.0\n",
      "media_count                      6984.0\n",
      "favourites_count                25961.0\n",
      "account_age_days                 5320.0\n",
      "follower_following_ratio    4303.117337\n",
      "user_id                       214201922\n",
      "degree_centrality              0.473684\n",
      "betweenness_centrality         0.102339\n",
      "closeness_centrality           0.140351\n",
      "eigenvector_centrality         0.324706\n",
      "pagerank                       0.063148\n",
      "influencer_score               1.154808\n",
      "community                             6\n",
      "screen_name                       Ninja\n",
      "\n",
      "âœ… Merged dataset for shroud:\n",
      "                                    0\n",
      "text_length                   61.6875\n",
      "word_count                       10.0\n",
      "has_media                        0.25\n",
      "has_url                        0.1875\n",
      "has_mentions                     0.25\n",
      "has_hashtags                    0.125\n",
      "favorite_count               628.0625\n",
      "retweet_count                   17.75\n",
      "reply_count                   45.6875\n",
      "bookmark_count                15.0625\n",
      "views                      125037.125\n",
      "engagement_rate              0.005253\n",
      "sentiment_polarity           0.126637\n",
      "sentiment_subjectivity       0.191567\n",
      "hour                            14.75\n",
      "is_weekend                       0.25\n",
      "followers_count             1843979.0\n",
      "friends_count                  1049.0\n",
      "listed_count                   1668.0\n",
      "statuses_count                 9830.0\n",
      "media_count                     986.0\n",
      "favourites_count               6392.0\n",
      "account_age_days               4364.0\n",
      "follower_following_ratio  1756.170476\n",
      "user_id                    1542453360\n",
      "degree_centrality            0.105263\n",
      "betweenness_centrality       0.061404\n",
      "closeness_centrality         0.070175\n",
      "eigenvector_centrality            0.0\n",
      "pagerank                     0.047586\n",
      "influencer_score             -0.35848\n",
      "community                           1\n",
      "screen_name                    shroud\n",
      "\n",
      "âœ… Merged dataset for Myth_:\n",
      "                                      0\n",
      "text_length                  105.923077\n",
      "word_count                    20.230769\n",
      "has_media                      0.461538\n",
      "has_url                             0.0\n",
      "has_mentions                   0.076923\n",
      "has_hashtags                   0.076923\n",
      "favorite_count              1220.384615\n",
      "retweet_count                      12.0\n",
      "reply_count                        53.0\n",
      "bookmark_count                23.384615\n",
      "views                     229042.153846\n",
      "engagement_rate                0.007232\n",
      "sentiment_polarity             0.043038\n",
      "sentiment_subjectivity         0.316686\n",
      "hour                          10.615385\n",
      "is_weekend                     0.230769\n",
      "followers_count               2404414.0\n",
      "friends_count                     632.0\n",
      "listed_count                     1157.0\n",
      "statuses_count                  20433.0\n",
      "media_count                      4493.0\n",
      "favourites_count                14036.0\n",
      "account_age_days                 4236.0\n",
      "follower_following_ratio    3798.442338\n",
      "user_id                      2163885564\n",
      "degree_centrality              0.157895\n",
      "betweenness_centrality              0.0\n",
      "closeness_centrality           0.112281\n",
      "eigenvector_centrality         0.146975\n",
      "pagerank                       0.030427\n",
      "influencer_score              -0.224005\n",
      "community                             6\n",
      "screen_name                       Myth_\n",
      "\n",
      "âœ… Merged dataset for DrLupo:\n",
      "                                      0\n",
      "text_length                  130.473684\n",
      "word_count                    22.105263\n",
      "has_media                      0.105263\n",
      "has_url                        0.684211\n",
      "has_mentions                   0.210526\n",
      "has_hashtags                   0.052632\n",
      "favorite_count              1191.736842\n",
      "retweet_count                      30.0\n",
      "reply_count                  277.684211\n",
      "bookmark_count               117.315789\n",
      "views                     514594.894737\n",
      "engagement_rate                1.717584\n",
      "sentiment_polarity             0.135607\n",
      "sentiment_subjectivity         0.384733\n",
      "hour                          11.473684\n",
      "is_weekend                     0.210526\n",
      "followers_count               1814855.0\n",
      "friends_count                    1255.0\n",
      "listed_count                     1185.0\n",
      "statuses_count                  41763.0\n",
      "media_count                      6906.0\n",
      "favourites_count                97974.0\n",
      "account_age_days                 3499.0\n",
      "follower_following_ratio    1444.948248\n",
      "user_id                      4140881832\n",
      "degree_centrality              0.263158\n",
      "betweenness_centrality         0.099415\n",
      "closeness_centrality           0.224561\n",
      "eigenvector_centrality         0.441571\n",
      "pagerank                       0.092181\n",
      "influencer_score               0.968799\n",
      "community                             6\n",
      "screen_name                      DrLupo\n",
      "\n",
      "âœ… Merged dataset for TimTheTatman:\n",
      "                                     0\n",
      "text_length                      121.6\n",
      "word_count                       20.25\n",
      "has_media                         0.35\n",
      "has_url                           0.75\n",
      "has_mentions                       0.3\n",
      "has_hashtags                       0.1\n",
      "favorite_count                 1386.15\n",
      "retweet_count                    48.25\n",
      "reply_count                       51.5\n",
      "bookmark_count                   39.15\n",
      "views                         117797.8\n",
      "engagement_rate               0.046276\n",
      "sentiment_polarity            0.063604\n",
      "sentiment_subjectivity        0.308452\n",
      "hour                             16.15\n",
      "is_weekend                        0.05\n",
      "followers_count              2817296.0\n",
      "friends_count                   1352.0\n",
      "listed_count                    1797.0\n",
      "statuses_count                 61195.0\n",
      "media_count                     4977.0\n",
      "favourites_count               18821.0\n",
      "account_age_days                4562.0\n",
      "follower_following_ratio   2082.258684\n",
      "user_id                      995979576\n",
      "degree_centrality             0.421053\n",
      "betweenness_centrality        0.122807\n",
      "closeness_centrality          0.168421\n",
      "eigenvector_centrality        0.346852\n",
      "pagerank                      0.108782\n",
      "influencer_score              1.157466\n",
      "community                            6\n",
      "screen_name               TimTheTatman\n",
      "\n",
      "âœ… Merged dataset for Syndicate:\n",
      "                                    0\n",
      "text_length                     101.0\n",
      "word_count                       17.7\n",
      "has_media                        0.45\n",
      "has_url                          0.45\n",
      "has_mentions                      0.4\n",
      "has_hashtags                      0.0\n",
      "favorite_count                 1099.9\n",
      "retweet_count                    22.9\n",
      "reply_count                      24.4\n",
      "bookmark_count                  20.55\n",
      "views                        91522.45\n",
      "engagement_rate              0.162852\n",
      "sentiment_polarity           0.183108\n",
      "sentiment_subjectivity       0.350167\n",
      "hour                             16.1\n",
      "is_weekend                       0.15\n",
      "followers_count             1958649.0\n",
      "friends_count                   232.0\n",
      "listed_count                   2812.0\n",
      "statuses_count               124167.0\n",
      "media_count                   25396.0\n",
      "favourites_count             131120.0\n",
      "account_age_days               5344.0\n",
      "follower_following_ratio  8406.218884\n",
      "user_id                     204089551\n",
      "degree_centrality            0.052632\n",
      "betweenness_centrality            0.0\n",
      "closeness_centrality          0.14152\n",
      "eigenvector_centrality       0.096637\n",
      "pagerank                     0.070607\n",
      "influencer_score            -0.218962\n",
      "community                           2\n",
      "screen_name                 Syndicate\n",
      "\n",
      "âœ… Merged dataset for Summit1g:\n",
      "                                   0\n",
      "text_length                    101.4\n",
      "word_count                     15.35\n",
      "has_media                        0.1\n",
      "has_url                         0.85\n",
      "has_mentions                    0.15\n",
      "has_hashtags                     0.0\n",
      "favorite_count                  83.0\n",
      "retweet_count                    7.8\n",
      "reply_count                      1.9\n",
      "bookmark_count                  0.25\n",
      "views                        23163.8\n",
      "engagement_rate             0.159523\n",
      "sentiment_polarity          0.116591\n",
      "sentiment_subjectivity       0.50375\n",
      "hour                            17.0\n",
      "is_weekend                      0.25\n",
      "followers_count            1000250.0\n",
      "friends_count                 1709.0\n",
      "listed_count                   993.0\n",
      "statuses_count               19813.0\n",
      "media_count                    911.0\n",
      "favourites_count             24155.0\n",
      "account_age_days              4298.0\n",
      "follower_following_ratio   584.94152\n",
      "user_id                   1708443876\n",
      "degree_centrality           0.210526\n",
      "betweenness_centrality      0.084795\n",
      "closeness_centrality        0.198142\n",
      "eigenvector_centrality      0.157002\n",
      "pagerank                    0.078617\n",
      "influencer_score            0.291109\n",
      "community                          1\n",
      "screen_name                 Summit1g\n",
      "âš ï¸ Skipping Pokimane: features file not found.\n",
      "\n",
      "âœ… Merged dataset for Tfue:\n",
      "                                      0\n",
      "text_length                   57.333333\n",
      "word_count                     9.833333\n",
      "has_media                      0.611111\n",
      "has_url                        0.055556\n",
      "has_mentions                   0.222222\n",
      "has_hashtags                   0.055556\n",
      "favorite_count             10873.555556\n",
      "retweet_count                737.666667\n",
      "reply_count                  183.166667\n",
      "bookmark_count               191.444444\n",
      "views                     661279.777778\n",
      "engagement_rate                0.575402\n",
      "sentiment_polarity            -0.034028\n",
      "sentiment_subjectivity         0.283333\n",
      "hour                          15.333333\n",
      "is_weekend                     0.111111\n",
      "followers_count               4066397.0\n",
      "friends_count                    1444.0\n",
      "listed_count                     1418.0\n",
      "statuses_count                   6086.0\n",
      "media_count                      1144.0\n",
      "favourites_count                19094.0\n",
      "account_age_days                 4031.0\n",
      "follower_following_ratio    2814.115571\n",
      "user_id                      2559865245\n",
      "degree_centrality              0.263158\n",
      "betweenness_centrality          0.01462\n",
      "closeness_centrality           0.146453\n",
      "eigenvector_centrality         0.370503\n",
      "pagerank                        0.05877\n",
      "influencer_score               0.569018\n",
      "community                             6\n",
      "screen_name                        Tfue\n",
      "\n",
      "âœ… Merged dataset for Jacksepticeye:\n",
      "                                      0\n",
      "text_length                    101.6875\n",
      "word_count                      18.4375\n",
      "has_media                        0.4375\n",
      "has_url                          0.0625\n",
      "has_mentions                     0.1875\n",
      "has_hashtags                        0.0\n",
      "favorite_count                32168.125\n",
      "retweet_count                    2223.0\n",
      "reply_count                       824.0\n",
      "bookmark_count                    814.0\n",
      "views                         675277.75\n",
      "engagement_rate               28.232583\n",
      "sentiment_polarity             0.159665\n",
      "sentiment_subjectivity         0.364905\n",
      "hour                             15.625\n",
      "is_weekend                       0.1875\n",
      "followers_count               7626884.0\n",
      "friends_count                     530.0\n",
      "listed_count                     5504.0\n",
      "statuses_count                  18925.0\n",
      "media_count                      1962.0\n",
      "favourites_count                60332.0\n",
      "account_age_days                 5730.0\n",
      "follower_following_ratio   14363.246704\n",
      "user_id                        77596200\n",
      "degree_centrality              0.105263\n",
      "betweenness_centrality         0.032164\n",
      "closeness_centrality           0.052632\n",
      "eigenvector_centrality              0.0\n",
      "pagerank                       0.029208\n",
      "influencer_score              -0.106235\n",
      "community                             1\n",
      "screen_name               Jacksepticeye\n",
      "âš ï¸ Skipping Valkyrae: features file not found.\n",
      "âš ï¸ Skipping Quackity: features file not found.\n",
      "\n",
      "âœ… Merged dataset for TheGrefg:\n",
      "                                      0\n",
      "text_length                   99.111111\n",
      "word_count                    16.444444\n",
      "has_media                      0.555556\n",
      "has_url                        0.388889\n",
      "has_mentions                   0.222222\n",
      "has_hashtags                   0.055556\n",
      "favorite_count              4575.833333\n",
      "retweet_count                431.611111\n",
      "reply_count                   24.444444\n",
      "bookmark_count                95.111111\n",
      "views                     216979.944444\n",
      "engagement_rate              121.443173\n",
      "sentiment_polarity                  0.0\n",
      "sentiment_subjectivity              0.0\n",
      "hour                          17.944444\n",
      "is_weekend                     0.277778\n",
      "followers_count               8387527.0\n",
      "friends_count                    1835.0\n",
      "listed_count                     2155.0\n",
      "statuses_count                  52147.0\n",
      "media_count                     17907.0\n",
      "favourites_count                85934.0\n",
      "account_age_days                 4536.0\n",
      "follower_following_ratio    4568.369826\n",
      "user_id                      1056396672\n",
      "degree_centrality                   0.0\n",
      "betweenness_centrality              0.0\n",
      "closeness_centrality                0.0\n",
      "eigenvector_centrality              0.0\n",
      "pagerank                       0.022759\n",
      "influencer_score              -0.340714\n",
      "community                             5\n",
      "screen_name                    TheGrefg\n",
      "\n",
      "âœ… Merged dataset for Jynxzi:\n",
      "                                            0\n",
      "text_length                           97.9375\n",
      "word_count                             17.625\n",
      "has_media                              0.5625\n",
      "has_url                                0.0625\n",
      "has_mentions                            0.625\n",
      "has_hashtags                            0.125\n",
      "favorite_count                     10579.1875\n",
      "retweet_count                        455.0625\n",
      "reply_count                          225.9375\n",
      "bookmark_count                       113.4375\n",
      "views                             324442.4375\n",
      "engagement_rate                      6.282664\n",
      "sentiment_polarity                   0.231763\n",
      "sentiment_subjectivity               0.357106\n",
      "hour                                     15.5\n",
      "is_weekend                              0.125\n",
      "followers_count                      609674.0\n",
      "friends_count                          1204.0\n",
      "listed_count                             93.0\n",
      "statuses_count                         1930.0\n",
      "media_count                             422.0\n",
      "favourites_count                       4636.0\n",
      "account_age_days                       2112.0\n",
      "follower_following_ratio           505.953527\n",
      "user_id                   1165011598672650240\n",
      "degree_centrality                    0.263158\n",
      "betweenness_centrality                    0.0\n",
      "closeness_centrality                 0.292398\n",
      "eigenvector_centrality                0.54275\n",
      "pagerank                             0.123573\n",
      "influencer_score                     1.020255\n",
      "community                                   6\n",
      "screen_name                            Jynxzi\n",
      "\n",
      "âœ… Merged dataset for markiplier:\n",
      "                                     0\n",
      "text_length                 109.133333\n",
      "word_count                   18.466667\n",
      "has_media                     0.333333\n",
      "has_url                       0.066667\n",
      "has_mentions                  0.533333\n",
      "has_hashtags                       0.2\n",
      "favorite_count                 71503.0\n",
      "retweet_count              5751.933333\n",
      "reply_count                1093.933333\n",
      "bookmark_count                  2983.0\n",
      "views                        1988540.2\n",
      "engagement_rate              20.085307\n",
      "sentiment_polarity            0.167222\n",
      "sentiment_subjectivity        0.281597\n",
      "hour                               7.4\n",
      "is_weekend                    0.266667\n",
      "followers_count             13865632.0\n",
      "friends_count                    382.0\n",
      "listed_count                    5555.0\n",
      "statuses_count                  9040.0\n",
      "media_count                     3150.0\n",
      "favourites_count                2350.0\n",
      "account_age_days                4838.0\n",
      "follower_following_ratio  36202.694517\n",
      "user_id                      517077573\n",
      "degree_centrality             0.157895\n",
      "betweenness_centrality             0.0\n",
      "closeness_centrality               0.0\n",
      "eigenvector_centrality             0.0\n",
      "pagerank                      0.022759\n",
      "influencer_score              0.251415\n",
      "community                            1\n",
      "screen_name                 markiplier\n",
      "âš ï¸ Skipping SSSniperWolf: features file not found.\n",
      "\n",
      "âœ… Merged dataset for OMGitsAliA:\n",
      "                                    0\n",
      "text_length                      73.7\n",
      "word_count                       13.1\n",
      "has_media                         0.9\n",
      "has_url                           0.1\n",
      "has_mentions                     0.35\n",
      "has_hashtags                     0.05\n",
      "favorite_count                3252.35\n",
      "retweet_count                    67.8\n",
      "reply_count                      43.9\n",
      "bookmark_count                  123.9\n",
      "views                        135393.2\n",
      "engagement_rate              0.505653\n",
      "sentiment_polarity           -0.01312\n",
      "sentiment_subjectivity       0.253595\n",
      "hour                             14.6\n",
      "is_weekend                        0.3\n",
      "followers_count             2383752.0\n",
      "friends_count                  1011.0\n",
      "listed_count                   1912.0\n",
      "statuses_count                62636.0\n",
      "media_count                   17161.0\n",
      "favourites_count              66820.0\n",
      "account_age_days               5469.0\n",
      "follower_following_ratio  2355.486166\n",
      "user_id                     155620461\n",
      "degree_centrality            0.157895\n",
      "betweenness_centrality        0.02924\n",
      "closeness_centrality         0.154799\n",
      "eigenvector_centrality       0.213502\n",
      "pagerank                     0.056291\n",
      "influencer_score             0.122382\n",
      "community                           2\n",
      "screen_name                OMGitsAliA\n",
      "\n",
      "âœ… Merged dataset for scump:\n",
      "                                    0\n",
      "text_length                     71.65\n",
      "word_count                      12.05\n",
      "has_media                        0.75\n",
      "has_url                           0.3\n",
      "has_mentions                     0.25\n",
      "has_hashtags                      0.0\n",
      "favorite_count                2422.45\n",
      "retweet_count                    67.8\n",
      "reply_count                     11.15\n",
      "bookmark_count                  59.05\n",
      "views                       113490.85\n",
      "engagement_rate              0.018252\n",
      "sentiment_polarity           0.159582\n",
      "sentiment_subjectivity       0.206667\n",
      "hour                             17.3\n",
      "is_weekend                        0.5\n",
      "followers_count             2240844.0\n",
      "friends_count                  2134.0\n",
      "listed_count                   1927.0\n",
      "statuses_count                57489.0\n",
      "media_count                    6551.0\n",
      "favourites_count              17048.0\n",
      "account_age_days               5184.0\n",
      "follower_following_ratio  1049.575644\n",
      "user_id                     272570677\n",
      "degree_centrality            0.052632\n",
      "betweenness_centrality            0.0\n",
      "closeness_centrality              0.0\n",
      "eigenvector_centrality            0.0\n",
      "pagerank                     0.022759\n",
      "influencer_score            -0.743308\n",
      "community                           6\n",
      "screen_name                     scump\n",
      "\n",
      "âœ… Merged dataset for LazarBeam:\n",
      "                                      0\n",
      "text_length                   64.428571\n",
      "word_count                    11.857143\n",
      "has_media                      0.642857\n",
      "has_url                             0.0\n",
      "has_mentions                   0.071429\n",
      "has_hashtags                        0.0\n",
      "favorite_count             26334.785714\n",
      "retweet_count                512.571429\n",
      "reply_count                  248.214286\n",
      "bookmark_count               434.928571\n",
      "views                     589137.357143\n",
      "engagement_rate                5.926775\n",
      "sentiment_polarity            -0.032143\n",
      "sentiment_subjectivity         0.445238\n",
      "hour                          10.071429\n",
      "is_weekend                     0.285714\n",
      "followers_count               2540149.0\n",
      "friends_count                    1381.0\n",
      "listed_count                     1017.0\n",
      "statuses_count                  14313.0\n",
      "media_count                      1768.0\n",
      "favourites_count                19027.0\n",
      "account_age_days                 3906.0\n",
      "follower_following_ratio    1838.023878\n",
      "user_id                      2830604556\n",
      "degree_centrality              0.105263\n",
      "betweenness_centrality              0.0\n",
      "closeness_centrality           0.129187\n",
      "eigenvector_centrality         0.146975\n",
      "pagerank                       0.030427\n",
      "influencer_score              -0.254085\n",
      "community                             2\n",
      "screen_name                   LazarBeam\n",
      "âš ï¸ Skipping Pokelawls: features file not found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load centrality data\n",
    "centrality_df = pd.read_csv(\"data/outputs/centrality/influencer_centrality.csv\")\n",
    "\n",
    "# Drop redundant profile fields (to avoid overlap with final_features)\n",
    "redundant_cols = ['followers_count', 'friends_count', 'statuses_count', 'name', 'screen_name']\n",
    "\n",
    "# List of influencer Twitter handles\n",
    "INFLUENCER_USERNAMES = [\n",
    "    \"Ninja\", \"shroud\", \"Myth_\", \"DrLupo\", \"TimTheTatman\", \"Syndicate\", \"Summit1g\", \"Pokimane\",\n",
    "    \"Tfue\", \"Jacksepticeye\", \"Valkyrae\", \"Quackity\", \"TheGrefg\", \"Jynxzi\", \"markiplier\",\n",
    "    \"SSSniperWolf\", \"OMGitsAliA\", \"scump\", \"LazarBeam\", \"Pokelawls\"\n",
    "]\n",
    "\n",
    "# Placeholder to store all merged datasets\n",
    "all_merged = []\n",
    "\n",
    "for influencer_screen_name in INFLUENCER_USERNAMES:\n",
    "    # Load or generate final_features for this influencer\n",
    "    # Replace this with your actual logic\n",
    "    try:\n",
    "        final_features = pd.read_csv(f\"data/outputs/engagement_features/{influencer_screen_name}_features.csv\")\n",
    "        final_features = final_features.loc[:, ~final_features.columns.str.contains('^Unnamed')]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âš ï¸ Skipping {influencer_screen_name}: features file not found.\")\n",
    "        continue\n",
    "\n",
    "    # Match centrality row\n",
    "    influencer_centrality = centrality_df[\n",
    "        centrality_df['screen_name'].str.lower() == influencer_screen_name.lower()\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    if influencer_centrality.empty:\n",
    "        print(f\"âš ï¸ Skipping {influencer_screen_name}: no centrality data found.\")\n",
    "        continue\n",
    "\n",
    "    influencer_centrality = influencer_centrality.drop(columns=redundant_cols, errors='ignore')\n",
    "\n",
    "    # Keep only \"mean\" row if final_features has multiple rows (mean/std/max)\n",
    "    if \"mean\" in final_features.index or final_features.shape[0] > 1:\n",
    "        try:\n",
    "            final_features = final_features.set_index(\"stat\").loc[[\"mean\"]].reset_index(drop=True)\n",
    "        except:\n",
    "            final_features = final_features.iloc[[0]]  # fallback to first row\n",
    "    else:\n",
    "        final_features = final_features.iloc[[0]]\n",
    "\n",
    "    # Merge horizontally\n",
    "    merged = pd.concat([final_features.reset_index(drop=True), influencer_centrality], axis=1)\n",
    "    merged[\"screen_name\"] = influencer_screen_name  # Add label for traceability\n",
    "\n",
    "    print(f\"\\nâœ… Merged dataset for {influencer_screen_name}:\")\n",
    "    print(merged.T)\n",
    "\n",
    "    all_merged.append(merged)\n",
    "\n",
    "# Optionally combine all into one DataFrame\n",
    "final_dataset = pd.concat(all_merged, ignore_index=True)\n",
    "\n",
    "# Save merged dataset\n",
    "final_dataset.to_csv(\"data/outputs/influencer_features_combined_all.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b308ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def parse_datetime(date_str: str) -> datetime | None:\n",
    "    if not date_str:\n",
    "        return None\n",
    "    return datetime.strptime(date_str, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "\n",
    "\n",
    "def get_sentiment(text: str) -> tuple[float, float]:\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
    "\n",
    "\n",
    "def extract_tweet_features(json_path: str) -> pd.DataFrame:\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    tweet_records = []\n",
    "    try:\n",
    "        instructions = data['tweets']['result']['timeline']['instructions']\n",
    "    except KeyError:\n",
    "        raise ValueError(\"Invalid JSON structure: Missing 'instructions'.\")\n",
    "\n",
    "    entries = []\n",
    "    for instr in instructions:\n",
    "        if instr.get(\"type\") == \"TimelineAddEntries\":\n",
    "            entries.extend(instr.get(\"entries\", []))\n",
    "        elif instr.get(\"entry\", {}).get(\"content\", {}).get(\"itemContent\"):\n",
    "            entries.append(instr[\"entry\"])  # Handle pinned tweets\n",
    "\n",
    "    for entry in entries:\n",
    "        content = entry.get(\"content\", {})\n",
    "        item_content = content.get(\"itemContent\", {})\n",
    "        tweet_result = item_content.get(\"tweet_results\", {}).get(\"result\", {})\n",
    "\n",
    "        if tweet_result.get(\"__typename\") != \"Tweet\":\n",
    "            continue\n",
    "\n",
    "        legacy = tweet_result.get(\"legacy\", {})\n",
    "        user_legacy = tweet_result.get(\"core\", {}).get(\"user_results\", {}).get(\"result\", {}).get(\"legacy\", {})\n",
    "\n",
    "        full_text = legacy.get(\"full_text\", \"\")\n",
    "        polarity, subjectivity = get_sentiment(full_text)\n",
    "\n",
    "        tweet_info = {\n",
    "            \"tweet_id\": legacy.get(\"id_str\"),\n",
    "            \"created_at\": parse_datetime(legacy.get(\"created_at\")),\n",
    "            \"full_text\": full_text,\n",
    "            \"like_count\": legacy.get(\"favorite_count\"),\n",
    "            \"retweet_count\": legacy.get(\"retweet_count\"),\n",
    "            \"reply_count\": legacy.get(\"reply_count\"),\n",
    "            \"quote_count\": legacy.get(\"quote_count\"),\n",
    "            \"view_count\": int(tweet_result.get(\"views\", {}).get(\"count\", 0)),\n",
    "            \"text_length\": len(full_text),\n",
    "            \"word_count\": len(full_text.split()),\n",
    "            \"has_media\": int(\"media\" in legacy),\n",
    "            \"has_url\": int(bool(legacy.get(\"urls\"))),\n",
    "            \"has_mentions\": int(bool(legacy.get(\"user_mentions\"))),\n",
    "            \"has_hashtags\": int(bool(legacy.get(\"hashtags\"))),\n",
    "            \"sentiment_polarity\": polarity,\n",
    "            \"sentiment_subjectivity\": subjectivity,\n",
    "            \"hour\": parse_datetime(legacy.get(\"created_at\")).hour if legacy.get(\"created_at\") else None,\n",
    "            \"is_weekend\": int(parse_datetime(legacy.get(\"created_at\")).weekday() >= 5) if legacy.get(\"created_at\") else None,\n",
    "            \"engagement_rate\": (\n",
    "                legacy.get(\"favorite_count\", 0) +\n",
    "                legacy.get(\"retweet_count\", 0) +\n",
    "                legacy.get(\"reply_count\", 0) +\n",
    "                legacy.get(\"quote_count\", 0)\n",
    "            ) / (int(tweet_result.get(\"views\", {}).get(\"count\", 1))),\n",
    "            \"_user_legacy\": user_legacy,\n",
    "        }\n",
    "\n",
    "        tweet_records.append(tweet_info)\n",
    "\n",
    "    df = pd.DataFrame(tweet_records)\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No valid tweets found in {json_path}\")\n",
    "    df = df.sort_values(\"created_at\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def aggregate_features(tweet_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    agg_map = {\n",
    "        \"text_length\": [\"mean\", \"std\", \"max\"],\n",
    "        \"word_count\": [\"mean\", \"std\", \"max\"],\n",
    "        \"has_media\": \"mean\",\n",
    "        \"has_url\": \"mean\",\n",
    "        \"has_mentions\": \"mean\",\n",
    "        \"has_hashtags\": \"mean\",\n",
    "        \"like_count\": [\"mean\", \"max\"],\n",
    "        \"retweet_count\": [\"mean\", \"max\"],\n",
    "        \"reply_count\": [\"mean\", \"max\"],\n",
    "        \"quote_count\": [\"mean\", \"max\"],\n",
    "        \"view_count\": [\"mean\", \"max\"],\n",
    "        \"engagement_rate\": [\"mean\", \"max\", \"std\"],\n",
    "        \"sentiment_polarity\": [\"mean\", \"std\"],\n",
    "        \"sentiment_subjectivity\": [\"mean\", \"std\"],\n",
    "        \"hour\": \"mean\",\n",
    "        \"is_weekend\": \"mean\"\n",
    "    }\n",
    "\n",
    "    agg_df = tweet_df.agg(agg_map)\n",
    "    agg_df.columns = ['{}_{}'.format(col[0], col[1]) if isinstance(col, tuple) else col for col in agg_df.columns]\n",
    "\n",
    "    user_info = tweet_df.iloc[0][\"_user_legacy\"]\n",
    "    created_at_user = parse_datetime(user_info.get(\"created_at\"))\n",
    "    account_age = (datetime.utcnow() - created_at_user.replace(tzinfo=None)).days if created_at_user else None\n",
    "\n",
    "    profile_features = {\n",
    "        \"followers_count\": user_info.get(\"followers_count\", 0),\n",
    "        \"friends_count\": user_info.get(\"friends_count\", 0),\n",
    "        \"listed_count\": user_info.get(\"listed_count\", 0),\n",
    "        \"statuses_count\": user_info.get(\"statuses_count\", 0),\n",
    "        \"media_count\": user_info.get(\"media_count\", 0),\n",
    "        \"favourites_count\": user_info.get(\"favourites_count\", 0),\n",
    "        \"account_age_days\": account_age,\n",
    "        \"follower_following_ratio\": user_info.get(\"followers_count\", 0) / (user_info.get(\"friends_count\", 0) + 1)\n",
    "    }\n",
    "\n",
    "    final_features = pd.concat(\n",
    "        [agg_df.reset_index(drop=True), pd.DataFrame([profile_features])], axis=1\n",
    "    )\n",
    "    return final_features\n",
    "\n",
    "\n",
    "def load_multiple_influencers(json_paths: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and concatenate tweet-level features from multiple influencers.\n",
    "    json_paths: dict {influencer_id: json_file_path}\n",
    "    Returns concatenated DataFrame with influencer_id column.\n",
    "    \"\"\"\n",
    "    all_tweets = []\n",
    "    failed = []\n",
    "\n",
    "    for influencer_id, path in json_paths.items():\n",
    "        try:\n",
    "            df = extract_tweet_features(path)\n",
    "            df['influencer_id'] = influencer_id\n",
    "            all_tweets.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to process {influencer_id} at {path}: {e}\")\n",
    "            failed.append(influencer_id)\n",
    "\n",
    "    if not all_tweets:\n",
    "        raise ValueError(\"No valid tweet data extracted. Check if JSON structure has changed or files are empty.\")\n",
    "\n",
    "    print(f\"âœ… Successfully processed {len(all_tweets)} influencers.\")\n",
    "    if failed:\n",
    "        print(f\"âš ï¸ Failed to process {len(failed)} influencers: {failed}\")\n",
    "\n",
    "    return pd.concat(all_tweets, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "def train_test_split_time_based(df: pd.DataFrame, split_ratio=0.8) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    train_list, test_list = [], []\n",
    "    for influencer_id, group in df.groupby(\"influencer_id\"):\n",
    "        group_sorted = group.sort_values(\"created_at\")\n",
    "        split_idx = int(len(group_sorted) * split_ratio)\n",
    "        train_list.append(group_sorted.iloc[:split_idx])\n",
    "        test_list.append(group_sorted.iloc[split_idx:])\n",
    "    return pd.concat(train_list).reset_index(drop=True), pd.concat(test_list).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677fc4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"data/raw/tweets/\"\n",
    "output_dir = \"data/outputs/engagement_features/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Auto-generate json_paths dict: {screen_name: full_path}\n",
    "json_paths = {\n",
    "    file.replace(\".json\", \"\"): os.path.join(input_dir, file)\n",
    "    for file in os.listdir(input_dir)\n",
    "    if file.endswith(\".json\")\n",
    "}\n",
    "\n",
    "print(f\"Found {len(json_paths)} influencer JSON files.\")\n",
    "\n",
    "# Load all influencers' tweet data into one DataFrame\n",
    "print(json_paths)\n",
    "all_tweets_df = load_multiple_influencers(json_paths)\n",
    "\n",
    "print(f\"Loaded tweets for {all_tweets_df['influencer_id'].nunique()} influencers, total {len(all_tweets_df)} tweets.\")\n",
    "\n",
    "# Split into train/test sets by time (80% train, 20% test)\n",
    "train_df, test_df = train_test_split_time_based(all_tweets_df, split_ratio=0.8)\n",
    "\n",
    "print(f\"Train set: {len(train_df)} tweets, Test set: {len(test_df)} tweets.\")\n",
    "\n",
    "# Aggregate features per influencer (using all tweets)\n",
    "agg_features_list = []\n",
    "for influencer_id in all_tweets_df['influencer_id'].unique():\n",
    "    inf_tweets = all_tweets_df[all_tweets_df['influencer_id'] == influencer_id]\n",
    "    agg_df = aggregate_features(inf_tweets)\n",
    "    agg_df['influencer_id'] = influencer_id\n",
    "    agg_features_list.append(agg_df)\n",
    "\n",
    "agg_features_df = pd.concat(agg_features_list, ignore_index=True)\n",
    "\n",
    "# Save aggregated features to CSV\n",
    "output_path = os.path.join(output_dir, \"aggregated_engagement_features.csv\")\n",
    "agg_features_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved aggregated features for {len(agg_features_df)} influencers to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wif3009",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
