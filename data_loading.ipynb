{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b91df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Collecting data for TheGrefg...\n",
      "✅ Profile saved for TheGrefg\n",
      "✅ Tweets saved for TheGrefg\n",
      "✅ Followers saved for TheGrefg\n",
      "✅ Following saved for TheGrefg\n",
      "\n",
      "📦 Collecting data for Jynxzi...\n",
      "✅ Profile saved for Jynxzi\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "✅ Tweets saved for Jynxzi\n",
      "✅ Followers saved for Jynxzi\n",
      "✅ Following saved for Jynxzi\n",
      "\n",
      "📦 Collecting data for markiplier...\n",
      "✅ Profile saved for markiplier\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "✅ Tweets saved for markiplier\n",
      "✅ Followers saved for markiplier\n",
      "✅ Following saved for markiplier\n",
      "\n",
      "📦 Collecting data for SSSniperWolf...\n",
      "✅ Profile saved for SSSniperWolf\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "✅ Tweets saved for SSSniperWolf\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "✅ Followers saved for SSSniperWolf\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "✅ Following saved for SSSniperWolf\n",
      "\n",
      "📦 Collecting data for OMGitsAliA...\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "✅ Profile saved for OMGitsAliA\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "✅ Tweets saved for OMGitsAliA\n",
      "✅ Followers saved for OMGitsAliA\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "✅ Following saved for OMGitsAliA\n",
      "\n",
      "📦 Collecting data for scump...\n",
      "✅ Profile saved for scump\n",
      "✅ Tweets saved for scump\n",
      "✅ Followers saved for scump\n",
      "✅ Following saved for scump\n",
      "\n",
      "📦 Collecting data for LazarBeam...\n",
      "✅ Profile saved for LazarBeam\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "✅ Tweets saved for LazarBeam\n",
      "✅ Followers saved for LazarBeam\n",
      "✅ Following saved for LazarBeam\n",
      "\n",
      "📦 Collecting data for Pokelawls...\n",
      "✅ Profile saved for Pokelawls\n",
      "⏳ 429 Too Many Requests. Retrying in 0.5s...\n",
      "✅ Tweets saved for Pokelawls\n",
      "✅ Followers saved for Pokelawls\n",
      "✅ Following saved for Pokelawls\n",
      "\n",
      "🎉 All data collected and saved per influencer.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "# Load API keys\n",
    "load_dotenv()\n",
    "BASE_URL = \"https://twitter241.p.rapidapi.com\"\n",
    "HEADERS = {\n",
    "    \"x-rapidapi-host\": \"twitter241.p.rapidapi.com\",\n",
    "    \"x-rapidapi-key\": \"056375d7f5mshd4546f4fb1a7f4ep129c82jsna85290da7d03\"\n",
    "}\n",
    "\n",
    "Influencer list\n",
    "INFLUENCER_USERNAMES = [\n",
    "    \"Ninja\", \"shroud\", \"Myth_\", \"DrLupo\", \"TimTheTatman\", \"Syndicate\", \"Summit1g\", \"Pokimane\",\n",
    "    \"Tfue\", \"Jacksepticeye\", \"Valkyrae\", \"Quackity\", \"TheGrefg\", \"Jynxzi\", \"markiplier\",\n",
    "    \"SSSniperWolf\", \"OMGitsAliA\", \"scump\", \"LazarBeam\", \"Pokelawls\"\n",
    "]\n",
    "\n",
    "\n",
    "# Retry decorator for 429 errors\n",
    "# Retry decorator: infinite retries with no delay\n",
    "\n",
    "\n",
    "def retry_on_429():\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            while True:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except HTTPError as e:\n",
    "                    if e.response.status_code == 429:\n",
    "                        print(f\"⏳ 429 Too Many Requests. Retrying in 0.5s...\")\n",
    "                        time.sleep(0.5)\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "\n",
    "# API calls\n",
    "@retry_on_429()\n",
    "def get_user_info(username):\n",
    "    url = f\"{BASE_URL}/user\"\n",
    "    params = {\"username\": username}\n",
    "    response = requests.get(url, headers=HEADERS, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "@retry_on_429()\n",
    "def get_user_followers(user_id, count=100):\n",
    "    url = f\"{BASE_URL}/followers\"\n",
    "    params = {\"user\": user_id, \"count\": count}\n",
    "    response = requests.get(url, headers=HEADERS, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "@retry_on_429()\n",
    "def get_user_following(user_id, count=100):\n",
    "    url = f\"{BASE_URL}/followings\"\n",
    "    params = {\"user\": user_id, \"count\": count}\n",
    "    response = requests.get(url, headers=HEADERS, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "@retry_on_429()\n",
    "def get_user_tweets(user_id, count=50):\n",
    "    url = f\"{BASE_URL}/user-tweets\"\n",
    "    params = {\"user\": user_id, \"count\": count}\n",
    "    response = requests.get(url, headers=HEADERS, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Output folders\n",
    "os.makedirs(\"data/raw/profiles\", exist_ok=True)\n",
    "os.makedirs(\"data/raw/followers\", exist_ok=True)\n",
    "os.makedirs(\"data/raw/following\", exist_ok=True)\n",
    "os.makedirs(\"data/raw/tweets\", exist_ok=True)\n",
    "\n",
    "# Collect data\n",
    "for username in INFLUENCER_USERNAMES:\n",
    "    print(f\"\\n📦 Collecting data for {username}...\")\n",
    "\n",
    "    user_info = get_user_info(username)\n",
    "    if not user_info:\n",
    "        print(f\"⚠️ Failed to fetch user info for {username}\")\n",
    "        continue\n",
    "\n",
    "    # Extract user ID from nested structure\n",
    "    user_data = user_info.get(\"result\", {}).get(\"data\", {}).get(\"user\", {}).get(\"result\", {})\n",
    "    user_id = user_data.get(\"rest_id\")\n",
    "\n",
    "    if not user_id:\n",
    "        print(f\"❌ User ID not found for {username}\")\n",
    "        continue\n",
    "\n",
    "    # Save profile\n",
    "    with open(f\"data/raw/profiles/{username}.json\", \"w\") as f:\n",
    "        json.dump(user_info, f, indent=2)\n",
    "    print(f\"✅ Profile saved for {username}\")\n",
    "\n",
    "    # Get and save tweets\n",
    "    tweets = get_user_tweets(user_id)\n",
    "    if tweets:\n",
    "        with open(f\"data/raw/tweets/{username}.json\", \"w\") as f:\n",
    "            json.dump([{\"tweets\": tweets}], f, indent=2)\n",
    "        print(f\"✅ Tweets saved for {username}\")\n",
    "\n",
    "    # Get and save followers\n",
    "    followers = get_user_followers(user_id)\n",
    "    if followers:\n",
    "        with open(f\"data/raw/followers/{username}.json\", \"w\") as f:\n",
    "            json.dump(followers, f, indent=2)\n",
    "        print(f\"✅ Followers saved for {username}\")\n",
    "\n",
    "    # Get and save following\n",
    "    following = get_user_following(user_id)\n",
    "    if following:\n",
    "        with open(f\"data/raw/following/{username}.json\", \"w\") as f:\n",
    "            json.dump(following, f, indent=2)\n",
    "        print(f\"✅ Following saved for {username}\")\n",
    "\n",
    "    # Delay to reduce risk of rate limits\n",
    "\n",
    "print(\"\\n🎉 All data collected and saved per influencer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "710b36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_json(json_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Extracts and aggregates tweet and profile features from an influencer's tweet JSON file.\"\"\"\n",
    "    \n",
    "    # Load tweet JSON\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract tweets\n",
    "    entries = data[0]['tweets']['result']['timeline']['instructions']\n",
    "    tweet_items = []\n",
    "    for instruction in entries:\n",
    "        if instruction.get('type') == \"TimelineAddEntries\":\n",
    "            for entry in instruction['entries']:\n",
    "                try:\n",
    "                    tweet = entry['content']['itemContent']['tweet_results']['result']\n",
    "                    tweet_items.append(tweet)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "    # Helper: parse timestamp\n",
    "    def parse_datetime(t): return datetime.strptime(t, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "\n",
    "    # Helper: sentiment\n",
    "    def get_sentiment(text):\n",
    "        blob = TextBlob(text)\n",
    "        return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
    "\n",
    "    # Extract features per tweet\n",
    "    records = []\n",
    "    for t in tweet_items:\n",
    "        legacy = t['legacy']\n",
    "        views = t.get('views', {}).get('count', '0')\n",
    "        text = legacy.get('full_text', '')\n",
    "        media = legacy.get('entities', {}).get('media', [])\n",
    "        urls = legacy.get('entities', {}).get('urls', [])\n",
    "        mentions = legacy.get('entities', {}).get('user_mentions', [])\n",
    "        hashtags = legacy.get('entities', {}).get('hashtags', [])\n",
    "        polarity, subjectivity = get_sentiment(text)\n",
    "\n",
    "        views_count = int(views.replace(',', '')) if views else 1\n",
    "        total_engagement = legacy['favorite_count'] + legacy['retweet_count'] + legacy['reply_count']\n",
    "        engagement_rate = total_engagement / views_count if views_count > 0 else 0\n",
    "\n",
    "        records.append({\n",
    "            \"created_at\": parse_datetime(legacy['created_at']),\n",
    "            \"text_length\": len(text),\n",
    "            \"word_count\": len(re.findall(r'\\w+', text)),\n",
    "            \"has_media\": int(bool(media)),\n",
    "            \"has_url\": int(bool(urls)),\n",
    "            \"has_mentions\": int(bool(mentions)),\n",
    "            \"has_hashtags\": int(bool(hashtags)),\n",
    "            \"favorite_count\": legacy['favorite_count'],\n",
    "            \"retweet_count\": legacy['retweet_count'],\n",
    "            \"reply_count\": legacy['reply_count'],\n",
    "            \"bookmark_count\": legacy.get('bookmark_count', 0),\n",
    "            \"views\": views_count,\n",
    "            \"engagement_rate\": engagement_rate,\n",
    "            \"sentiment_polarity\": polarity,\n",
    "            \"sentiment_subjectivity\": subjectivity,\n",
    "            \"hour\": parse_datetime(legacy['created_at']).hour,\n",
    "            \"weekday\": parse_datetime(legacy['created_at']).weekday(),\n",
    "            \"is_weekend\": int(parse_datetime(legacy['created_at']).weekday() >= 5),\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No valid tweets found in JSON.\")\n",
    "\n",
    "    # === Aggregation ===\n",
    "    agg_features = {\n",
    "        \"text_length\": [\"mean\", \"std\", \"max\"],\n",
    "        \"word_count\": [\"mean\", \"std\", \"max\"],\n",
    "        \"has_media\": \"mean\",\n",
    "        \"has_url\": \"mean\",\n",
    "        \"has_mentions\": \"mean\",\n",
    "        \"has_hashtags\": \"mean\",\n",
    "        \"favorite_count\": [\"mean\", \"max\"],\n",
    "        \"retweet_count\": [\"mean\", \"max\"],\n",
    "        \"reply_count\": [\"mean\", \"max\"],\n",
    "        \"bookmark_count\": [\"mean\", \"max\"],\n",
    "        \"views\": [\"mean\", \"max\"],\n",
    "        \"engagement_rate\": [\"mean\", \"max\", \"std\"],\n",
    "        \"sentiment_polarity\": [\"mean\", \"std\"],\n",
    "        \"sentiment_subjectivity\": [\"mean\", \"std\"],\n",
    "        \"hour\": [\"mean\"],\n",
    "        \"is_weekend\": \"mean\"\n",
    "    }\n",
    "\n",
    "    agg_df = df.agg(agg_features)\n",
    "    agg_df.columns = ['{}_{}'.format(col[0], col[1]) if isinstance(col, tuple) else col for col in agg_df.columns]\n",
    "\n",
    "    # === Add user profile features ===\n",
    "    user_info = tweet_items[0]['core']['user_results']['result']['legacy']\n",
    "    created_at_user = parse_datetime(user_info['created_at'])\n",
    "    profile_features = {\n",
    "        \"followers_count\": user_info[\"followers_count\"],\n",
    "        \"friends_count\": user_info[\"friends_count\"],\n",
    "        \"listed_count\": user_info[\"listed_count\"],\n",
    "        \"statuses_count\": user_info[\"statuses_count\"],\n",
    "        \"media_count\": user_info[\"media_count\"],\n",
    "        \"favourites_count\": user_info[\"favourites_count\"],\n",
    "        \"account_age_days\": (datetime.utcnow() - created_at_user.replace(tzinfo=None)).days,\n",
    "        \"follower_following_ratio\": user_info[\"followers_count\"] / (user_info[\"friends_count\"] + 1)\n",
    "    }\n",
    "\n",
    "    final_features = pd.concat([agg_df.reset_index(drop=True), pd.DataFrame([profile_features])], axis=1)\n",
    "    return final_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "872a10cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: TheGrefg\n",
      "✅ Saved: OMGitsAliA\n",
      "✅ Saved: LazarBeam\n",
      "✅ Saved: Myth_\n",
      "✅ Saved: Jynxzi\n",
      "❌ Error processing Pokelawls: 'legacy'\n",
      "✅ Saved: Jacksepticeye\n",
      "✅ Saved: Summit1g\n",
      "✅ Saved: scump\n",
      "✅ Saved: markiplier\n",
      "✅ Saved: Tfue\n",
      "✅ Saved: DrLupo\n",
      "✅ Saved: TimTheTatman\n",
      "✅ Saved: shroud\n",
      "✅ Saved: Syndicate\n",
      "❌ Error processing Pokimane: No valid tweets found in JSON.\n",
      "✅ Saved: Ninja\n",
      "❌ Error processing SSSniperWolf: 'legacy'\n",
      "❌ Error processing Valkyrae: 'legacy'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "input_dir = \"data/raw/tweets/\"\n",
    "output_dir = \"data/outputs/engagement_features/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(input_dir):\n",
    "    if file.endswith(\".json\"):\n",
    "        screen_name = file.replace(\".json\", \"\")\n",
    "        try:\n",
    "            feature_df = extract_features_from_json(os.path.join(input_dir, file))\n",
    "            feature_df.to_csv(f\"{output_dir}/{screen_name}_features.csv\", index=False)\n",
    "            print(f\"✅ Saved: {screen_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {screen_name}: {e}\")\n",
    "\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_features.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7a240935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Merged dataset for Ninja:\n",
      "                                      0\n",
      "text_length                  104.647059\n",
      "word_count                    18.294118\n",
      "has_media                      0.705882\n",
      "has_url                        0.117647\n",
      "has_mentions                   0.588235\n",
      "has_hashtags                   0.058824\n",
      "favorite_count              3147.411765\n",
      "retweet_count                251.411765\n",
      "reply_count                   56.882353\n",
      "bookmark_count               251.176471\n",
      "views                     217888.705882\n",
      "engagement_rate               18.627375\n",
      "sentiment_polarity             0.172638\n",
      "sentiment_subjectivity         0.292157\n",
      "hour                          16.235294\n",
      "is_weekend                     0.235294\n",
      "followers_count               6527829.0\n",
      "friends_count                    1516.0\n",
      "listed_count                     3577.0\n",
      "statuses_count                  46063.0\n",
      "media_count                      6984.0\n",
      "favourites_count                25961.0\n",
      "account_age_days                 5320.0\n",
      "follower_following_ratio    4303.117337\n",
      "user_id                       214201922\n",
      "degree_centrality              0.473684\n",
      "betweenness_centrality         0.102339\n",
      "closeness_centrality           0.140351\n",
      "eigenvector_centrality         0.324706\n",
      "pagerank                       0.063148\n",
      "influencer_score               1.154808\n",
      "community                             6\n",
      "screen_name                       Ninja\n",
      "\n",
      "✅ Merged dataset for shroud:\n",
      "                                    0\n",
      "text_length                   61.6875\n",
      "word_count                       10.0\n",
      "has_media                        0.25\n",
      "has_url                        0.1875\n",
      "has_mentions                     0.25\n",
      "has_hashtags                    0.125\n",
      "favorite_count               628.0625\n",
      "retweet_count                   17.75\n",
      "reply_count                   45.6875\n",
      "bookmark_count                15.0625\n",
      "views                      125037.125\n",
      "engagement_rate              0.005253\n",
      "sentiment_polarity           0.126637\n",
      "sentiment_subjectivity       0.191567\n",
      "hour                            14.75\n",
      "is_weekend                       0.25\n",
      "followers_count             1843979.0\n",
      "friends_count                  1049.0\n",
      "listed_count                   1668.0\n",
      "statuses_count                 9830.0\n",
      "media_count                     986.0\n",
      "favourites_count               6392.0\n",
      "account_age_days               4364.0\n",
      "follower_following_ratio  1756.170476\n",
      "user_id                    1542453360\n",
      "degree_centrality            0.105263\n",
      "betweenness_centrality       0.061404\n",
      "closeness_centrality         0.070175\n",
      "eigenvector_centrality            0.0\n",
      "pagerank                     0.047586\n",
      "influencer_score             -0.35848\n",
      "community                           1\n",
      "screen_name                    shroud\n",
      "\n",
      "✅ Merged dataset for Myth_:\n",
      "                                      0\n",
      "text_length                  105.923077\n",
      "word_count                    20.230769\n",
      "has_media                      0.461538\n",
      "has_url                             0.0\n",
      "has_mentions                   0.076923\n",
      "has_hashtags                   0.076923\n",
      "favorite_count              1220.384615\n",
      "retweet_count                      12.0\n",
      "reply_count                        53.0\n",
      "bookmark_count                23.384615\n",
      "views                     229042.153846\n",
      "engagement_rate                0.007232\n",
      "sentiment_polarity             0.043038\n",
      "sentiment_subjectivity         0.316686\n",
      "hour                          10.615385\n",
      "is_weekend                     0.230769\n",
      "followers_count               2404414.0\n",
      "friends_count                     632.0\n",
      "listed_count                     1157.0\n",
      "statuses_count                  20433.0\n",
      "media_count                      4493.0\n",
      "favourites_count                14036.0\n",
      "account_age_days                 4236.0\n",
      "follower_following_ratio    3798.442338\n",
      "user_id                      2163885564\n",
      "degree_centrality              0.157895\n",
      "betweenness_centrality              0.0\n",
      "closeness_centrality           0.112281\n",
      "eigenvector_centrality         0.146975\n",
      "pagerank                       0.030427\n",
      "influencer_score              -0.224005\n",
      "community                             6\n",
      "screen_name                       Myth_\n",
      "\n",
      "✅ Merged dataset for DrLupo:\n",
      "                                      0\n",
      "text_length                  130.473684\n",
      "word_count                    22.105263\n",
      "has_media                      0.105263\n",
      "has_url                        0.684211\n",
      "has_mentions                   0.210526\n",
      "has_hashtags                   0.052632\n",
      "favorite_count              1191.736842\n",
      "retweet_count                      30.0\n",
      "reply_count                  277.684211\n",
      "bookmark_count               117.315789\n",
      "views                     514594.894737\n",
      "engagement_rate                1.717584\n",
      "sentiment_polarity             0.135607\n",
      "sentiment_subjectivity         0.384733\n",
      "hour                          11.473684\n",
      "is_weekend                     0.210526\n",
      "followers_count               1814855.0\n",
      "friends_count                    1255.0\n",
      "listed_count                     1185.0\n",
      "statuses_count                  41763.0\n",
      "media_count                      6906.0\n",
      "favourites_count                97974.0\n",
      "account_age_days                 3499.0\n",
      "follower_following_ratio    1444.948248\n",
      "user_id                      4140881832\n",
      "degree_centrality              0.263158\n",
      "betweenness_centrality         0.099415\n",
      "closeness_centrality           0.224561\n",
      "eigenvector_centrality         0.441571\n",
      "pagerank                       0.092181\n",
      "influencer_score               0.968799\n",
      "community                             6\n",
      "screen_name                      DrLupo\n",
      "\n",
      "✅ Merged dataset for TimTheTatman:\n",
      "                                     0\n",
      "text_length                      121.6\n",
      "word_count                       20.25\n",
      "has_media                         0.35\n",
      "has_url                           0.75\n",
      "has_mentions                       0.3\n",
      "has_hashtags                       0.1\n",
      "favorite_count                 1386.15\n",
      "retweet_count                    48.25\n",
      "reply_count                       51.5\n",
      "bookmark_count                   39.15\n",
      "views                         117797.8\n",
      "engagement_rate               0.046276\n",
      "sentiment_polarity            0.063604\n",
      "sentiment_subjectivity        0.308452\n",
      "hour                             16.15\n",
      "is_weekend                        0.05\n",
      "followers_count              2817296.0\n",
      "friends_count                   1352.0\n",
      "listed_count                    1797.0\n",
      "statuses_count                 61195.0\n",
      "media_count                     4977.0\n",
      "favourites_count               18821.0\n",
      "account_age_days                4562.0\n",
      "follower_following_ratio   2082.258684\n",
      "user_id                      995979576\n",
      "degree_centrality             0.421053\n",
      "betweenness_centrality        0.122807\n",
      "closeness_centrality          0.168421\n",
      "eigenvector_centrality        0.346852\n",
      "pagerank                      0.108782\n",
      "influencer_score              1.157466\n",
      "community                            6\n",
      "screen_name               TimTheTatman\n",
      "\n",
      "✅ Merged dataset for Syndicate:\n",
      "                                    0\n",
      "text_length                     101.0\n",
      "word_count                       17.7\n",
      "has_media                        0.45\n",
      "has_url                          0.45\n",
      "has_mentions                      0.4\n",
      "has_hashtags                      0.0\n",
      "favorite_count                 1099.9\n",
      "retweet_count                    22.9\n",
      "reply_count                      24.4\n",
      "bookmark_count                  20.55\n",
      "views                        91522.45\n",
      "engagement_rate              0.162852\n",
      "sentiment_polarity           0.183108\n",
      "sentiment_subjectivity       0.350167\n",
      "hour                             16.1\n",
      "is_weekend                       0.15\n",
      "followers_count             1958649.0\n",
      "friends_count                   232.0\n",
      "listed_count                   2812.0\n",
      "statuses_count               124167.0\n",
      "media_count                   25396.0\n",
      "favourites_count             131120.0\n",
      "account_age_days               5344.0\n",
      "follower_following_ratio  8406.218884\n",
      "user_id                     204089551\n",
      "degree_centrality            0.052632\n",
      "betweenness_centrality            0.0\n",
      "closeness_centrality          0.14152\n",
      "eigenvector_centrality       0.096637\n",
      "pagerank                     0.070607\n",
      "influencer_score            -0.218962\n",
      "community                           2\n",
      "screen_name                 Syndicate\n",
      "\n",
      "✅ Merged dataset for Summit1g:\n",
      "                                   0\n",
      "text_length                    101.4\n",
      "word_count                     15.35\n",
      "has_media                        0.1\n",
      "has_url                         0.85\n",
      "has_mentions                    0.15\n",
      "has_hashtags                     0.0\n",
      "favorite_count                  83.0\n",
      "retweet_count                    7.8\n",
      "reply_count                      1.9\n",
      "bookmark_count                  0.25\n",
      "views                        23163.8\n",
      "engagement_rate             0.159523\n",
      "sentiment_polarity          0.116591\n",
      "sentiment_subjectivity       0.50375\n",
      "hour                            17.0\n",
      "is_weekend                      0.25\n",
      "followers_count            1000250.0\n",
      "friends_count                 1709.0\n",
      "listed_count                   993.0\n",
      "statuses_count               19813.0\n",
      "media_count                    911.0\n",
      "favourites_count             24155.0\n",
      "account_age_days              4298.0\n",
      "follower_following_ratio   584.94152\n",
      "user_id                   1708443876\n",
      "degree_centrality           0.210526\n",
      "betweenness_centrality      0.084795\n",
      "closeness_centrality        0.198142\n",
      "eigenvector_centrality      0.157002\n",
      "pagerank                    0.078617\n",
      "influencer_score            0.291109\n",
      "community                          1\n",
      "screen_name                 Summit1g\n",
      "⚠️ Skipping Pokimane: features file not found.\n",
      "\n",
      "✅ Merged dataset for Tfue:\n",
      "                                      0\n",
      "text_length                   57.333333\n",
      "word_count                     9.833333\n",
      "has_media                      0.611111\n",
      "has_url                        0.055556\n",
      "has_mentions                   0.222222\n",
      "has_hashtags                   0.055556\n",
      "favorite_count             10873.555556\n",
      "retweet_count                737.666667\n",
      "reply_count                  183.166667\n",
      "bookmark_count               191.444444\n",
      "views                     661279.777778\n",
      "engagement_rate                0.575402\n",
      "sentiment_polarity            -0.034028\n",
      "sentiment_subjectivity         0.283333\n",
      "hour                          15.333333\n",
      "is_weekend                     0.111111\n",
      "followers_count               4066397.0\n",
      "friends_count                    1444.0\n",
      "listed_count                     1418.0\n",
      "statuses_count                   6086.0\n",
      "media_count                      1144.0\n",
      "favourites_count                19094.0\n",
      "account_age_days                 4031.0\n",
      "follower_following_ratio    2814.115571\n",
      "user_id                      2559865245\n",
      "degree_centrality              0.263158\n",
      "betweenness_centrality          0.01462\n",
      "closeness_centrality           0.146453\n",
      "eigenvector_centrality         0.370503\n",
      "pagerank                        0.05877\n",
      "influencer_score               0.569018\n",
      "community                             6\n",
      "screen_name                        Tfue\n",
      "\n",
      "✅ Merged dataset for Jacksepticeye:\n",
      "                                      0\n",
      "text_length                    101.6875\n",
      "word_count                      18.4375\n",
      "has_media                        0.4375\n",
      "has_url                          0.0625\n",
      "has_mentions                     0.1875\n",
      "has_hashtags                        0.0\n",
      "favorite_count                32168.125\n",
      "retweet_count                    2223.0\n",
      "reply_count                       824.0\n",
      "bookmark_count                    814.0\n",
      "views                         675277.75\n",
      "engagement_rate               28.232583\n",
      "sentiment_polarity             0.159665\n",
      "sentiment_subjectivity         0.364905\n",
      "hour                             15.625\n",
      "is_weekend                       0.1875\n",
      "followers_count               7626884.0\n",
      "friends_count                     530.0\n",
      "listed_count                     5504.0\n",
      "statuses_count                  18925.0\n",
      "media_count                      1962.0\n",
      "favourites_count                60332.0\n",
      "account_age_days                 5730.0\n",
      "follower_following_ratio   14363.246704\n",
      "user_id                        77596200\n",
      "degree_centrality              0.105263\n",
      "betweenness_centrality         0.032164\n",
      "closeness_centrality           0.052632\n",
      "eigenvector_centrality              0.0\n",
      "pagerank                       0.029208\n",
      "influencer_score              -0.106235\n",
      "community                             1\n",
      "screen_name               Jacksepticeye\n",
      "⚠️ Skipping Valkyrae: features file not found.\n",
      "⚠️ Skipping Quackity: features file not found.\n",
      "\n",
      "✅ Merged dataset for TheGrefg:\n",
      "                                      0\n",
      "text_length                   99.111111\n",
      "word_count                    16.444444\n",
      "has_media                      0.555556\n",
      "has_url                        0.388889\n",
      "has_mentions                   0.222222\n",
      "has_hashtags                   0.055556\n",
      "favorite_count              4575.833333\n",
      "retweet_count                431.611111\n",
      "reply_count                   24.444444\n",
      "bookmark_count                95.111111\n",
      "views                     216979.944444\n",
      "engagement_rate              121.443173\n",
      "sentiment_polarity                  0.0\n",
      "sentiment_subjectivity              0.0\n",
      "hour                          17.944444\n",
      "is_weekend                     0.277778\n",
      "followers_count               8387527.0\n",
      "friends_count                    1835.0\n",
      "listed_count                     2155.0\n",
      "statuses_count                  52147.0\n",
      "media_count                     17907.0\n",
      "favourites_count                85934.0\n",
      "account_age_days                 4536.0\n",
      "follower_following_ratio    4568.369826\n",
      "user_id                      1056396672\n",
      "degree_centrality                   0.0\n",
      "betweenness_centrality              0.0\n",
      "closeness_centrality                0.0\n",
      "eigenvector_centrality              0.0\n",
      "pagerank                       0.022759\n",
      "influencer_score              -0.340714\n",
      "community                             5\n",
      "screen_name                    TheGrefg\n",
      "\n",
      "✅ Merged dataset for Jynxzi:\n",
      "                                            0\n",
      "text_length                           97.9375\n",
      "word_count                             17.625\n",
      "has_media                              0.5625\n",
      "has_url                                0.0625\n",
      "has_mentions                            0.625\n",
      "has_hashtags                            0.125\n",
      "favorite_count                     10579.1875\n",
      "retweet_count                        455.0625\n",
      "reply_count                          225.9375\n",
      "bookmark_count                       113.4375\n",
      "views                             324442.4375\n",
      "engagement_rate                      6.282664\n",
      "sentiment_polarity                   0.231763\n",
      "sentiment_subjectivity               0.357106\n",
      "hour                                     15.5\n",
      "is_weekend                              0.125\n",
      "followers_count                      609674.0\n",
      "friends_count                          1204.0\n",
      "listed_count                             93.0\n",
      "statuses_count                         1930.0\n",
      "media_count                             422.0\n",
      "favourites_count                       4636.0\n",
      "account_age_days                       2112.0\n",
      "follower_following_ratio           505.953527\n",
      "user_id                   1165011598672650240\n",
      "degree_centrality                    0.263158\n",
      "betweenness_centrality                    0.0\n",
      "closeness_centrality                 0.292398\n",
      "eigenvector_centrality                0.54275\n",
      "pagerank                             0.123573\n",
      "influencer_score                     1.020255\n",
      "community                                   6\n",
      "screen_name                            Jynxzi\n",
      "\n",
      "✅ Merged dataset for markiplier:\n",
      "                                     0\n",
      "text_length                 109.133333\n",
      "word_count                   18.466667\n",
      "has_media                     0.333333\n",
      "has_url                       0.066667\n",
      "has_mentions                  0.533333\n",
      "has_hashtags                       0.2\n",
      "favorite_count                 71503.0\n",
      "retweet_count              5751.933333\n",
      "reply_count                1093.933333\n",
      "bookmark_count                  2983.0\n",
      "views                        1988540.2\n",
      "engagement_rate              20.085307\n",
      "sentiment_polarity            0.167222\n",
      "sentiment_subjectivity        0.281597\n",
      "hour                               7.4\n",
      "is_weekend                    0.266667\n",
      "followers_count             13865632.0\n",
      "friends_count                    382.0\n",
      "listed_count                    5555.0\n",
      "statuses_count                  9040.0\n",
      "media_count                     3150.0\n",
      "favourites_count                2350.0\n",
      "account_age_days                4838.0\n",
      "follower_following_ratio  36202.694517\n",
      "user_id                      517077573\n",
      "degree_centrality             0.157895\n",
      "betweenness_centrality             0.0\n",
      "closeness_centrality               0.0\n",
      "eigenvector_centrality             0.0\n",
      "pagerank                      0.022759\n",
      "influencer_score              0.251415\n",
      "community                            1\n",
      "screen_name                 markiplier\n",
      "⚠️ Skipping SSSniperWolf: features file not found.\n",
      "\n",
      "✅ Merged dataset for OMGitsAliA:\n",
      "                                    0\n",
      "text_length                      73.7\n",
      "word_count                       13.1\n",
      "has_media                         0.9\n",
      "has_url                           0.1\n",
      "has_mentions                     0.35\n",
      "has_hashtags                     0.05\n",
      "favorite_count                3252.35\n",
      "retweet_count                    67.8\n",
      "reply_count                      43.9\n",
      "bookmark_count                  123.9\n",
      "views                        135393.2\n",
      "engagement_rate              0.505653\n",
      "sentiment_polarity           -0.01312\n",
      "sentiment_subjectivity       0.253595\n",
      "hour                             14.6\n",
      "is_weekend                        0.3\n",
      "followers_count             2383752.0\n",
      "friends_count                  1011.0\n",
      "listed_count                   1912.0\n",
      "statuses_count                62636.0\n",
      "media_count                   17161.0\n",
      "favourites_count              66820.0\n",
      "account_age_days               5469.0\n",
      "follower_following_ratio  2355.486166\n",
      "user_id                     155620461\n",
      "degree_centrality            0.157895\n",
      "betweenness_centrality        0.02924\n",
      "closeness_centrality         0.154799\n",
      "eigenvector_centrality       0.213502\n",
      "pagerank                     0.056291\n",
      "influencer_score             0.122382\n",
      "community                           2\n",
      "screen_name                OMGitsAliA\n",
      "\n",
      "✅ Merged dataset for scump:\n",
      "                                    0\n",
      "text_length                     71.65\n",
      "word_count                      12.05\n",
      "has_media                        0.75\n",
      "has_url                           0.3\n",
      "has_mentions                     0.25\n",
      "has_hashtags                      0.0\n",
      "favorite_count                2422.45\n",
      "retweet_count                    67.8\n",
      "reply_count                     11.15\n",
      "bookmark_count                  59.05\n",
      "views                       113490.85\n",
      "engagement_rate              0.018252\n",
      "sentiment_polarity           0.159582\n",
      "sentiment_subjectivity       0.206667\n",
      "hour                             17.3\n",
      "is_weekend                        0.5\n",
      "followers_count             2240844.0\n",
      "friends_count                  2134.0\n",
      "listed_count                   1927.0\n",
      "statuses_count                57489.0\n",
      "media_count                    6551.0\n",
      "favourites_count              17048.0\n",
      "account_age_days               5184.0\n",
      "follower_following_ratio  1049.575644\n",
      "user_id                     272570677\n",
      "degree_centrality            0.052632\n",
      "betweenness_centrality            0.0\n",
      "closeness_centrality              0.0\n",
      "eigenvector_centrality            0.0\n",
      "pagerank                     0.022759\n",
      "influencer_score            -0.743308\n",
      "community                           6\n",
      "screen_name                     scump\n",
      "\n",
      "✅ Merged dataset for LazarBeam:\n",
      "                                      0\n",
      "text_length                   64.428571\n",
      "word_count                    11.857143\n",
      "has_media                      0.642857\n",
      "has_url                             0.0\n",
      "has_mentions                   0.071429\n",
      "has_hashtags                        0.0\n",
      "favorite_count             26334.785714\n",
      "retweet_count                512.571429\n",
      "reply_count                  248.214286\n",
      "bookmark_count               434.928571\n",
      "views                     589137.357143\n",
      "engagement_rate                5.926775\n",
      "sentiment_polarity            -0.032143\n",
      "sentiment_subjectivity         0.445238\n",
      "hour                          10.071429\n",
      "is_weekend                     0.285714\n",
      "followers_count               2540149.0\n",
      "friends_count                    1381.0\n",
      "listed_count                     1017.0\n",
      "statuses_count                  14313.0\n",
      "media_count                      1768.0\n",
      "favourites_count                19027.0\n",
      "account_age_days                 3906.0\n",
      "follower_following_ratio    1838.023878\n",
      "user_id                      2830604556\n",
      "degree_centrality              0.105263\n",
      "betweenness_centrality              0.0\n",
      "closeness_centrality           0.129187\n",
      "eigenvector_centrality         0.146975\n",
      "pagerank                       0.030427\n",
      "influencer_score              -0.254085\n",
      "community                             2\n",
      "screen_name                   LazarBeam\n",
      "⚠️ Skipping Pokelawls: features file not found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load centrality data\n",
    "centrality_df = pd.read_csv(\"data/outputs/centrality/influencer_centrality.csv\")\n",
    "\n",
    "# Drop redundant profile fields (to avoid overlap with final_features)\n",
    "redundant_cols = ['followers_count', 'friends_count', 'statuses_count', 'name', 'screen_name']\n",
    "\n",
    "# List of influencer Twitter handles\n",
    "INFLUENCER_USERNAMES = [\n",
    "    \"Ninja\", \"shroud\", \"Myth_\", \"DrLupo\", \"TimTheTatman\", \"Syndicate\", \"Summit1g\", \"Pokimane\",\n",
    "    \"Tfue\", \"Jacksepticeye\", \"Valkyrae\", \"Quackity\", \"TheGrefg\", \"Jynxzi\", \"markiplier\",\n",
    "    \"SSSniperWolf\", \"OMGitsAliA\", \"scump\", \"LazarBeam\", \"Pokelawls\"\n",
    "]\n",
    "\n",
    "# Placeholder to store all merged datasets\n",
    "all_merged = []\n",
    "\n",
    "for influencer_screen_name in INFLUENCER_USERNAMES:\n",
    "    # Load or generate final_features for this influencer\n",
    "    # Replace this with your actual logic\n",
    "    try:\n",
    "        final_features = pd.read_csv(f\"data/outputs/engagement_features/{influencer_screen_name}_features.csv\")\n",
    "        final_features = final_features.loc[:, ~final_features.columns.str.contains('^Unnamed')]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️ Skipping {influencer_screen_name}: features file not found.\")\n",
    "        continue\n",
    "\n",
    "    # Match centrality row\n",
    "    influencer_centrality = centrality_df[\n",
    "        centrality_df['screen_name'].str.lower() == influencer_screen_name.lower()\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    if influencer_centrality.empty:\n",
    "        print(f\"⚠️ Skipping {influencer_screen_name}: no centrality data found.\")\n",
    "        continue\n",
    "\n",
    "    influencer_centrality = influencer_centrality.drop(columns=redundant_cols, errors='ignore')\n",
    "\n",
    "    # Keep only \"mean\" row if final_features has multiple rows (mean/std/max)\n",
    "    if \"mean\" in final_features.index or final_features.shape[0] > 1:\n",
    "        try:\n",
    "            final_features = final_features.set_index(\"stat\").loc[[\"mean\"]].reset_index(drop=True)\n",
    "        except:\n",
    "            final_features = final_features.iloc[[0]]  # fallback to first row\n",
    "    else:\n",
    "        final_features = final_features.iloc[[0]]\n",
    "\n",
    "    # Merge horizontally\n",
    "    merged = pd.concat([final_features.reset_index(drop=True), influencer_centrality], axis=1)\n",
    "    merged[\"screen_name\"] = influencer_screen_name  # Add label for traceability\n",
    "\n",
    "    print(f\"\\n✅ Merged dataset for {influencer_screen_name}:\")\n",
    "    print(merged.T)\n",
    "\n",
    "    all_merged.append(merged)\n",
    "\n",
    "# Optionally combine all into one DataFrame\n",
    "final_dataset = pd.concat(all_merged, ignore_index=True)\n",
    "\n",
    "# Save merged dataset\n",
    "final_dataset.to_csv(\"data/outputs/influencer_features_combined_all.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b308ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def parse_datetime(date_str: str) -> datetime | None:\n",
    "    if not date_str:\n",
    "        return None\n",
    "    return datetime.strptime(date_str, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "\n",
    "\n",
    "def get_sentiment(text: str) -> tuple[float, float]:\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
    "\n",
    "\n",
    "def extract_tweet_features(json_path: str) -> pd.DataFrame:\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    tweet_records = []\n",
    "    try:\n",
    "        instructions = data['tweets']['result']['timeline']['instructions']\n",
    "    except KeyError:\n",
    "        raise ValueError(\"Invalid JSON structure: Missing 'instructions'.\")\n",
    "\n",
    "    entries = []\n",
    "    for instr in instructions:\n",
    "        if instr.get(\"type\") == \"TimelineAddEntries\":\n",
    "            entries.extend(instr.get(\"entries\", []))\n",
    "        elif instr.get(\"entry\", {}).get(\"content\", {}).get(\"itemContent\"):\n",
    "            entries.append(instr[\"entry\"])  # Handle pinned tweets\n",
    "\n",
    "    for entry in entries:\n",
    "        content = entry.get(\"content\", {})\n",
    "        item_content = content.get(\"itemContent\", {})\n",
    "        tweet_result = item_content.get(\"tweet_results\", {}).get(\"result\", {})\n",
    "\n",
    "        if tweet_result.get(\"__typename\") != \"Tweet\":\n",
    "            continue\n",
    "\n",
    "        legacy = tweet_result.get(\"legacy\", {})\n",
    "        user_legacy = tweet_result.get(\"core\", {}).get(\"user_results\", {}).get(\"result\", {}).get(\"legacy\", {})\n",
    "\n",
    "        full_text = legacy.get(\"full_text\", \"\")\n",
    "        polarity, subjectivity = get_sentiment(full_text)\n",
    "\n",
    "        tweet_info = {\n",
    "            \"tweet_id\": legacy.get(\"id_str\"),\n",
    "            \"created_at\": parse_datetime(legacy.get(\"created_at\")),\n",
    "            \"full_text\": full_text,\n",
    "            \"like_count\": legacy.get(\"favorite_count\"),\n",
    "            \"retweet_count\": legacy.get(\"retweet_count\"),\n",
    "            \"reply_count\": legacy.get(\"reply_count\"),\n",
    "            \"quote_count\": legacy.get(\"quote_count\"),\n",
    "            \"view_count\": int(tweet_result.get(\"views\", {}).get(\"count\", 0)),\n",
    "            \"text_length\": len(full_text),\n",
    "            \"word_count\": len(full_text.split()),\n",
    "            \"has_media\": int(\"media\" in legacy),\n",
    "            \"has_url\": int(bool(legacy.get(\"urls\"))),\n",
    "            \"has_mentions\": int(bool(legacy.get(\"user_mentions\"))),\n",
    "            \"has_hashtags\": int(bool(legacy.get(\"hashtags\"))),\n",
    "            \"sentiment_polarity\": polarity,\n",
    "            \"sentiment_subjectivity\": subjectivity,\n",
    "            \"hour\": parse_datetime(legacy.get(\"created_at\")).hour if legacy.get(\"created_at\") else None,\n",
    "            \"is_weekend\": int(parse_datetime(legacy.get(\"created_at\")).weekday() >= 5) if legacy.get(\"created_at\") else None,\n",
    "            \"engagement_rate\": (\n",
    "                legacy.get(\"favorite_count\", 0) +\n",
    "                legacy.get(\"retweet_count\", 0) +\n",
    "                legacy.get(\"reply_count\", 0) +\n",
    "                legacy.get(\"quote_count\", 0)\n",
    "            ) / (int(tweet_result.get(\"views\", {}).get(\"count\", 1))),\n",
    "            \"_user_legacy\": user_legacy,\n",
    "        }\n",
    "\n",
    "        tweet_records.append(tweet_info)\n",
    "\n",
    "    df = pd.DataFrame(tweet_records)\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No valid tweets found in {json_path}\")\n",
    "    df = df.sort_values(\"created_at\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def aggregate_features(tweet_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    agg_map = {\n",
    "        \"text_length\": [\"mean\", \"std\", \"max\"],\n",
    "        \"word_count\": [\"mean\", \"std\", \"max\"],\n",
    "        \"has_media\": \"mean\",\n",
    "        \"has_url\": \"mean\",\n",
    "        \"has_mentions\": \"mean\",\n",
    "        \"has_hashtags\": \"mean\",\n",
    "        \"like_count\": [\"mean\", \"max\"],\n",
    "        \"retweet_count\": [\"mean\", \"max\"],\n",
    "        \"reply_count\": [\"mean\", \"max\"],\n",
    "        \"quote_count\": [\"mean\", \"max\"],\n",
    "        \"view_count\": [\"mean\", \"max\"],\n",
    "        \"engagement_rate\": [\"mean\", \"max\", \"std\"],\n",
    "        \"sentiment_polarity\": [\"mean\", \"std\"],\n",
    "        \"sentiment_subjectivity\": [\"mean\", \"std\"],\n",
    "        \"hour\": \"mean\",\n",
    "        \"is_weekend\": \"mean\"\n",
    "    }\n",
    "\n",
    "    agg_df = tweet_df.agg(agg_map)\n",
    "    agg_df.columns = ['{}_{}'.format(col[0], col[1]) if isinstance(col, tuple) else col for col in agg_df.columns]\n",
    "\n",
    "    user_info = tweet_df.iloc[0][\"_user_legacy\"]\n",
    "    created_at_user = parse_datetime(user_info.get(\"created_at\"))\n",
    "    account_age = (datetime.utcnow() - created_at_user.replace(tzinfo=None)).days if created_at_user else None\n",
    "\n",
    "    profile_features = {\n",
    "        \"followers_count\": user_info.get(\"followers_count\", 0),\n",
    "        \"friends_count\": user_info.get(\"friends_count\", 0),\n",
    "        \"listed_count\": user_info.get(\"listed_count\", 0),\n",
    "        \"statuses_count\": user_info.get(\"statuses_count\", 0),\n",
    "        \"media_count\": user_info.get(\"media_count\", 0),\n",
    "        \"favourites_count\": user_info.get(\"favourites_count\", 0),\n",
    "        \"account_age_days\": account_age,\n",
    "        \"follower_following_ratio\": user_info.get(\"followers_count\", 0) / (user_info.get(\"friends_count\", 0) + 1)\n",
    "    }\n",
    "\n",
    "    final_features = pd.concat(\n",
    "        [agg_df.reset_index(drop=True), pd.DataFrame([profile_features])], axis=1\n",
    "    )\n",
    "    return final_features\n",
    "\n",
    "\n",
    "def load_multiple_influencers(json_paths: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and concatenate tweet-level features from multiple influencers.\n",
    "    json_paths: dict {influencer_id: json_file_path}\n",
    "    Returns concatenated DataFrame with influencer_id column.\n",
    "    \"\"\"\n",
    "    all_tweets = []\n",
    "    failed = []\n",
    "\n",
    "    for influencer_id, path in json_paths.items():\n",
    "        try:\n",
    "            df = extract_tweet_features(path)\n",
    "            df['influencer_id'] = influencer_id\n",
    "            all_tweets.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to process {influencer_id} at {path}: {e}\")\n",
    "            failed.append(influencer_id)\n",
    "\n",
    "    if not all_tweets:\n",
    "        raise ValueError(\"No valid tweet data extracted. Check if JSON structure has changed or files are empty.\")\n",
    "\n",
    "    print(f\"✅ Successfully processed {len(all_tweets)} influencers.\")\n",
    "    if failed:\n",
    "        print(f\"⚠️ Failed to process {len(failed)} influencers: {failed}\")\n",
    "\n",
    "    return pd.concat(all_tweets, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "def train_test_split_time_based(df: pd.DataFrame, split_ratio=0.8) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    train_list, test_list = [], []\n",
    "    for influencer_id, group in df.groupby(\"influencer_id\"):\n",
    "        group_sorted = group.sort_values(\"created_at\")\n",
    "        split_idx = int(len(group_sorted) * split_ratio)\n",
    "        train_list.append(group_sorted.iloc[:split_idx])\n",
    "        test_list.append(group_sorted.iloc[split_idx:])\n",
    "    return pd.concat(train_list).reset_index(drop=True), pd.concat(test_list).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677fc4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"data/raw/tweets/\"\n",
    "output_dir = \"data/outputs/engagement_features/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Auto-generate json_paths dict: {screen_name: full_path}\n",
    "json_paths = {\n",
    "    file.replace(\".json\", \"\"): os.path.join(input_dir, file)\n",
    "    for file in os.listdir(input_dir)\n",
    "    if file.endswith(\".json\")\n",
    "}\n",
    "\n",
    "print(f\"Found {len(json_paths)} influencer JSON files.\")\n",
    "\n",
    "# Load all influencers' tweet data into one DataFrame\n",
    "print(json_paths)\n",
    "all_tweets_df = load_multiple_influencers(json_paths)\n",
    "\n",
    "print(f\"Loaded tweets for {all_tweets_df['influencer_id'].nunique()} influencers, total {len(all_tweets_df)} tweets.\")\n",
    "\n",
    "# Split into train/test sets by time (80% train, 20% test)\n",
    "train_df, test_df = train_test_split_time_based(all_tweets_df, split_ratio=0.8)\n",
    "\n",
    "print(f\"Train set: {len(train_df)} tweets, Test set: {len(test_df)} tweets.\")\n",
    "\n",
    "# Aggregate features per influencer (using all tweets)\n",
    "agg_features_list = []\n",
    "for influencer_id in all_tweets_df['influencer_id'].unique():\n",
    "    inf_tweets = all_tweets_df[all_tweets_df['influencer_id'] == influencer_id]\n",
    "    agg_df = aggregate_features(inf_tweets)\n",
    "    agg_df['influencer_id'] = influencer_id\n",
    "    agg_features_list.append(agg_df)\n",
    "\n",
    "agg_features_df = pd.concat(agg_features_list, ignore_index=True)\n",
    "\n",
    "# Save aggregated features to CSV\n",
    "output_path = os.path.join(output_dir, \"aggregated_engagement_features.csv\")\n",
    "agg_features_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved aggregated features for {len(agg_features_df)} influencers to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wif3009",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
